{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\David\\.cache\\kagglehub\\datasets\\spscientist\\students-performance-in-exams\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download data from kaggle\n",
    "file_path = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\n",
    "print(\"Path to dataset files:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline with student exam data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from csv file, return pandas dataframe\n",
    "def extract(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data extraction complete.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data and return it\n",
    "def transform(data):\n",
    "    # Filter students, include only students that completed the preparation course\n",
    "    transformed_data = data.loc[data[\"test preparation course\"] == \"completed\"]\n",
    "    print(\"Data transformation complete.\")\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into sqlite database\n",
    "def load(data, db_path):\n",
    "    # Establish db connection\n",
    "    con = sqlite3.connect(db_path)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # Create table if not existing\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS students (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            gender VARCHAR(10),\n",
    "            math_score INTEGER,\n",
    "            reading_score INTEGER,\n",
    "            writing_score INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Insert students into table\n",
    "    for _, stud in data.iterrows():\n",
    "        cur.execute(\"INSERT INTO students (gender, math_score, reading_score, writing_score) VALUES (?, ?, ?, ?)\", [stud[\"gender\"], stud[\"math score\"], stud[\"reading score\"], stud[\"writing score\"]])\n",
    "    print(\"Inserted \"+str(len(data))+\" student entries.\")\n",
    "\n",
    "    # Close db connection\n",
    "    cur.close()\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "    print(\"Data load complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the etl pipeline into one function\n",
    "def run_etl_pipeline():\n",
    "    try:\n",
    "        # Define paths\n",
    "        csv_path = file_path+\"/StudentsPerformance.csv\"\n",
    "        db_path = \"students.db\"\n",
    "\n",
    "        data = extract(csv_path)\n",
    "\n",
    "        transformed_data = transform(data)\n",
    "\n",
    "        load(transformed_data, db_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete.\n",
      "Data transformation complete.\n",
      "Inserted 358 student entries.\n",
      "Data load complete.\n"
     ]
    }
   ],
   "source": [
    "# Execute the etl pipeline\n",
    "run_etl_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
